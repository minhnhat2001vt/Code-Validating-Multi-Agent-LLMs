{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogen\n",
      "  Downloading autogen-0.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pyautogen==0.5.2 (from autogen)\n",
      "  Downloading pyautogen-0.5.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting diskcache (from pyautogen==0.5.2->autogen)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting docker (from pyautogen==0.5.2->autogen)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting flaml (from pyautogen==0.5.2->autogen)\n",
      "  Downloading FLAML-2.3.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: openai>=1.3 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from pyautogen==0.5.2->autogen) (1.57.0)\n",
      "Requirement already satisfied: packaging in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from pyautogen==0.5.2->autogen) (24.0)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from pyautogen==0.5.2->autogen) (2.10.3)\n",
      "Requirement already satisfied: python-dotenv in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from pyautogen==0.5.2->autogen) (1.0.1)\n",
      "Requirement already satisfied: termcolor in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from pyautogen==0.5.2->autogen) (2.4.0)\n",
      "Requirement already satisfied: tiktoken in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from pyautogen==0.5.2->autogen) (0.8.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from pyautogen==0.5.2->autogen) (1.26.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from openai>=1.3->pyautogen==0.5.2->autogen) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from openai>=1.3->pyautogen==0.5.2->autogen) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from openai>=1.3->pyautogen==0.5.2->autogen) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from openai>=1.3->pyautogen==0.5.2->autogen) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from openai>=1.3->pyautogen==0.5.2->autogen) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from openai>=1.3->pyautogen==0.5.2->autogen) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from openai>=1.3->pyautogen==0.5.2->autogen) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.5.2->autogen) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.5.2->autogen) (2.27.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from docker->pyautogen==0.5.2->autogen) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from docker->pyautogen==0.5.2->autogen) (2.2.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from tiktoken->pyautogen==0.5.2->autogen) (2023.12.25)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen==0.5.2->autogen) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen==0.5.2->autogen) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.5.2->autogen) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.5.2->autogen) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.5.2->autogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/macos/anaconda3/envs/DeepLearning/lib/python3.10/site-packages (from requests>=2.26.0->docker->pyautogen==0.5.2->autogen) (3.3.2)\n",
      "Downloading autogen-0.5.2-py3-none-any.whl (13 kB)\n",
      "Downloading pyautogen-0.5.2-py3-none-any.whl (419 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.6/419.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading FLAML-2.3.2-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: flaml, diskcache, docker, pyautogen, autogen\n",
      "Successfully installed autogen-0.5.2 diskcache-5.6.3 docker-7.1.0 flaml-2.3.2 pyautogen-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-agent conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 agents\n",
    "import getpass\n",
    "\n",
    "API_key = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m      3\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m API_key\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/DeepLearning/lib/python3.10/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = API_key\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_1 = ConversableAgent(\n",
    "    \"agent_P\",\n",
    "    system_message=\"Your name is agent_P, and you are a professional Data Scientist.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-3.5-turbo\", \"temperature\": 0.9, \"api_key\": API_key}]},\n",
    "    human_input_mode=\"NEVER\", # Never ask for human input\n",
    ")\n",
    "\n",
    "agent_2 = ConversableAgent(\n",
    "    \"agent_D\",\n",
    "    system_message=\"Your name is agent_D, and you are a student major in Data Science.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-3.5-turbo\", \"temperature\": 0.9, \"api_key\": API_key}]},\n",
    "    human_input_mode=\"NEVER\", # Never ask for human input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent_P\u001b[0m (to agent_D):\n",
      "\n",
      "agent_D, Let discuss about Multi-dimensional Analysis\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_D\u001b[0m (to agent_P):\n",
      "\n",
      "Multi-dimensional analysis, also known as multi-dimensional data analysis or OLAP (Online Analytical Processing), is a method of analyzing data that allows for complex and interactive analysis of large datasets from multiple perspectives or dimensions. This type of analysis is commonly used in data warehousing and business intelligence to uncover patterns, trends, and insights that may not be apparent with traditional two-dimensional analysis methods. By organizing data into multi-dimensional structures, analysts can perform various types of analysis, including drilling down into specific data points, pivoting or rotating dimensions, and creating dynamic and interactive visualizations for better decision-making. Do you have any specific aspect of multi-dimensional analysis that you would like to discuss?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_P\u001b[0m (to agent_D):\n",
      "\n",
      "agent_P: Multi-dimensional analysis is a powerful tool for gaining deeper insights from complex data. One aspect of multi-dimensional analysis that I find particularly interesting is the concept of \"slicing and dicing\" data. This refers to the ability to slice the data along different dimensions and then dice it further to explore specific subsets of the data. By slicing and dicing data in various ways, analysts can uncover hidden patterns, correlations, and outliers that may not be apparent when looking at the data as a whole. It allows for a more granular and detailed analysis of the data, leading to more informed decision-making. What are your thoughts on the slicing and dicing aspect of multi-dimensional analysis?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_D\u001b[0m (to agent_P):\n",
      "\n",
      "Slicing and dicing data is indeed a fundamental aspect of multi-dimensional analysis that provides analysts with the flexibility to examine data from various perspectives and dimensions. By slicing data, analysts can isolate specific subsets of data based on a particular dimension or attribute, allowing for focused analysis on that subset. Dicing, on the other hand, involves breaking down the sliced data further into even smaller subsets for closer examination. This iterative process of slicing and dicing helps identify trends, anomalies, and relationships within the data that might not be obvious when looking at the data as a whole. It also helps in exploring the data in a more interactive and dynamic way, enabling analysts to ask more targeted questions and derive actionable insights. Overall, slicing and dicing data play a crucial role in enhancing the analytical capabilities of multi-dimensional analysis and can lead to more meaningful and data-driven decisions.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_P\u001b[0m (to agent_D):\n",
      "\n",
      "It's great to hear your insights on the importance of slicing and dicing data in multi-dimensional analysis. This iterative process allows analysts to dive deeper into the data, uncovering valuable insights and patterns that can drive informed decision-making. By slicing and dicing data along different dimensions, analysts can explore correlations, trends, and outliers that may not be immediately apparent, leading to a more thorough understanding of the data. This dynamic approach to data analysis enables organizations to extract maximum value from their data assets and gain a competitive edge in today's data-driven business landscape. If you have any specific examples or use cases where slicing and dicing data has been particularly impactful, I'd love to hear more about them.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent_D\u001b[0m (to agent_P):\n",
      "\n",
      "One common example where slicing and dicing data in multi-dimensional analysis is particularly impactful is in retail sales analysis. Retailers often have large datasets containing information about sales transactions, including details such as products, locations, time periods, customer demographics, and more. By slicing the data along different dimensions such as product categories, sales channels, customer segments, or geographic regions, analysts can gain valuable insights into sales performance, trends, and customer behavior.\n",
      "\n",
      "For example, analysts can slice the sales data by product category to identify top-selling products or product categories, understand seasonality trends, and optimize inventory management. They can then dice the data further by customer segments to analyze purchase behavior, customer preferences, and customer lifetime value. By combining slicing and dicing techniques, analysts can uncover correlations between different dimensions, such as the impact of marketing campaigns on sales by product category or customer segment.\n",
      "\n",
      "This multi-dimensional analysis approach allows retailers to make data-driven decisions, such as optimizing product assortments, tailoring marketing strategies to specific customer segments, identifying cross-selling opportunities, and forecasting sales more accurately. By leveraging slicing and dicing techniques in multi-dimensional analysis, organizations can harness the power of their data to drive business growth and enhance customer satisfaction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = agent_1.initiate_chat(\n",
    "    agent_2,\n",
    "    message=\"agent_D, Let discuss about Multi-dimensional Analysis\",\n",
    "    max_turns=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 agents Driver (AI) and Passenger (Human) to play guess-my-number\n",
    "driver = ConversableAgent(\n",
    "    \"driver\",\n",
    "    system_message=\"You are playing a game of guess-my-number. You have the \" \n",
    "    \"number 101 in your mind, and I will try to guess it. \"\n",
    "    \"If my guess was too high, say 'too high', if my guess was too low, say 'too low'. \",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-3.5-turbo\", \"temperature\": 0.9, \"api_key\": API_key}]},\n",
    "    is_termination_msg=lambda msg: \"101\" in msg[\"content\"], # Terminate if the guessed number is correct\n",
    "    human_input_mode=\"NEVER\", # always ask for human input\n",
    ")\n",
    "\n",
    "human_passenger = ConversableAgent(\n",
    "    \"human_passenger\",\n",
    "    llm_config=False,\n",
    "    human_input_mode=\"ALWAYS\", # always ask for human input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mdriver\u001b[0m (to human_passenger):\n",
      "\n",
      "The distance from Ho Chi Minh City to Vung Tau is between 70 and 120 km. Could you guess it?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_passenger\u001b[0m (to driver):\n",
      "\n",
      "100\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mdriver\u001b[0m (to human_passenger):\n",
      "\n",
      "Too low.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_passenger\u001b[0m (to driver):\n",
      "\n",
      "107\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mdriver\u001b[0m (to human_passenger):\n",
      "\n",
      "Too high.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_passenger\u001b[0m (to driver):\n",
      "\n",
      "104\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mdriver\u001b[0m (to human_passenger):\n",
      "\n",
      "Too high.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_passenger\u001b[0m (to driver):\n",
      "\n",
      "101\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_2 = driver.initiate_chat(\n",
    "    human_passenger,\n",
    "    message=\"The distance from Ho Chi Minh City to Vung Tau is between 70 and 120 km. Could you guess it?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
